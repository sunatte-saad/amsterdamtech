{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Foundation II\n",
    "\n",
    "Welcome to the first part of the EDA module and more specifically to the pandas module No 2! Today we will actually solve some questions around famous datasets uning the `pandas` module! \n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "For this module, we will **not** need any new modules. We will use the `sklearn` module to load one opf your datasets.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Boston house prices dataset\n",
    "\n",
    "You can find all the information you need about the Boston dataset [here](https://www.kaggle.com/datasets/vikrishnan/boston-house-prices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyhere import here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the Boston House prices dataset. Using the Boston housing dataset, create a new DataFrame containing only the columns 'CRIM', 'ZN', 'INDUS', and 'NOX'. (*Hint: the dataset is located on the highest level, on the path Module_3/data under the name housing.csv*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
    "\n",
    "df = pd.read_csv(here(\"Module_3\", \"data\", \"housing.csv\"), header=None, sep=\"\\s+\",names=column_names)\n",
    "new_df = df[['CRIM', 'ZN', 'INDUS', 'NOX']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Find the average 'CRIM' value for each value of 'ZN' in the new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_crim = new_df.groupby('ZN')['CRIM'].mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Add a new column to the new DataFrame called 'CRIM_ZN_RATIO' which is the ratio of 'CRIM' to 'ZN'. Let's do it in two different ways!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['CRIM_ZN_RATIO'] = new_df['CRIM'] / new_df['ZN']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Create a new DataFrame containing only the rows where 'CRIM_ZN_RATIO' is greater than 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_ratio_df = new_df[new_df['CRIM_ZN_RATIO'] > 0.1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Using the original DataFrame, create a new DataFrame containing only the rows where the value of 'CHAS' is 1 and the value of 'AGE' is greater than 60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chas_df = df[df['CHAS'] == 1]\n",
    "age_df = chas_df[chas_df['AGE'] > 60]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Using the new DataFrame from question 5, find the average value of 'DIS' for each value of 'RAD'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_dis = age_df.groupby('RAD')['DIS'].mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Using the original DataFrame, create a new DataFrame containing only the columns 'NOX', 'DIS', and 'TAX'. Then, sort the DataFrame by the values of 'NOX' in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nox_dis_tax_df = df[['NOX', 'DIS', 'TAX']]\n",
    "sorted_df = nox_dis_tax_df.sort_values('NOX')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Using the new DataFrame from question 7, find the top 5 values of 'DIS' for the lowest 5 values of 'NOX'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_dis = sorted_df['DIS'].sort_values(ascending=False).head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Diabtes dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the diabetes dataset from the scikit-learn package and assign it to a variable. Using only built-in pandas functions, create a new DataFrame that only contains the rows where the 'age' column is greater than 50 and the 'bmi' column is less than 30. Then, calculate the mean and standard deviation of the 'bp' column for these rows and return them in a dictionary format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets as datasets\n",
    "\n",
    "diabetes_data = datasets.load_diabetes()\n",
    "df = pd.DataFrame(diabetes_data.data, columns=diabetes_data.feature_names)\n",
    "\n",
    "\n",
    "df_filtered = df[(df['age'] > 50) & (df['bmi'] < 30)]\n",
    "result = {\"mean\": df_filtered[\"bp\"].mean(), \"std\": df_filtered[\"bp\"].std()}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Using the diabetes dataset that you loaded in question 1, use built-in pandas functions to create a new DataFrame that contains all rows where the 'bp' column is greater than 130, and the 's1' column is less than -0.2. Then, Using this DataFrame, create a new column called 'bmi_normalized' which is the result of the 'bmi' column minus the mean of the 'bmi' column and divide by the standard deviation of the 'bmi' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[(df['bp'] > 130) & (df['s1'] < -0.2)]\n",
    "df_filtered['bmi_normalized'] = (df_filtered['bmi'] - df_filtered['bmi'].mean()) / df_filtered['bmi'].std()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Using the diabetes dataset that you loaded in question 1, create a new column called 'bmi_category' that categorizes the 'bmi' column into three categories: 'normal', 'overweight', and 'obese'. The new column should be added to the original DataFrame. Then, Create another column called 'bmi_category_num' that replaces 'normal' with 0, 'overweight' with 1 and 'obese' with 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bmi_category'] = 'normal'\n",
    "df.loc[(df['bmi'] > 24.9) & (df['bmi'] <= 29.9), 'bmi_category'] = 'overweight'\n",
    "df.loc[df['bmi'] > 29.9, 'bmi_category'] = 'obese'\n",
    "df['bmi_category_num'] = df['bmi_category'].map({'normal': 0, 'overweight': 1, 'obese': 2})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Using the diabetes dataset that you loaded in question 1, use built-in pandas functions to calculate the median 'bmi' for each 'age' group, and return a new DataFrame containing the results. Also, group the data by 'age' and calculate the mean of the 'bp' column for each age group, then merge the two DataFrame on 'age' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_bmi_by_age = df.groupby([\"age\"])[\"bmi\"].median().reset_index()\n",
    "mean_bp_by_age = df.groupby([\"age\"])[\"bp\"].mean().reset_index()\n",
    "result = pd.merge(median_bmi_by_age, mean_bp_by_age, on='age')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Using the diabetes dataset that you loaded in question 1, create a pivot table that shows the mean 'bmi' for each unique value of the 'bp' column, grouped by the 'age' column. Then, use the pivot table to select the rows where the mean 'bmi' is greater than 30 and return a new DataFrame that contains these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table = df.pivot_table(values='bmi', index='age', columns='bp', aggfunc='mean')\n",
    "pivot_table_filtered = pivot_table[pivot_table > 30]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Using the diabetes dataset that you loaded in question 1, use built-in pandas functions to group the data by 'age' and calculate the mean of the 'bp' column for each age group. Then, calculate the correlation between each column of the DataFrame and the 'bp' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby(['age'])['bp'].mean()\n",
    "correlations = df.corr()['bp']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Using the diabetes dataset that you loaded in question 1, create a new DataFrame that only contains the rows where the 's1' column is greater than 0.1 and the 's2' column is less than -0.2. Then, Use the .apply() method to create a new column in the DataFrame called \"s1_s2_product\" which is the product of the 's1' and 's2' columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[(df['s1'] > 0.1) & (df['s2'] < -0.2)]\n",
    "df_filtered[\"s1_s2_product\"] = df_filtered[\"s1\"]*df_filtered[\"s2\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Using the diabetes dataset that you loaded in question 1, use built-in pandas functions to sort the DataFrame by the 'bmi' column in descending order, and then by the 'age' column in ascending order. Then, use the .drop_duplicates() method to remove any duplicate rows from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df.sort_values(by=['bmi', 'age'], ascending=[False, True])\n",
    "df_deduplicated = df_sorted.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pmsc-data-science-2022-xQONswq6-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35990521bd9d01a47262615948ff745c00af78816c915031e531315dcc5c61db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
